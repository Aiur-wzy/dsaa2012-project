{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Label Noise Mitigation & Class Confusion\n",
        "\n",
        "This notebook compares standard cross-entropy training with a label-smoothing variant and visualizes class confusion for both models. It also includes a stub for simulating noisy labels to stress-test robustness strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Define the dataset path and common hyperparameters used across experiments. Training runs may take several minutes depending on hardware. Adjust batch size or epochs downward for quick sanity checks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from fer import (\n",
        "    EMOTION_LABELS,\n",
        "    EmotionCNN,\n",
        "    build_dataloaders,\n",
        "    evaluate,\n",
        "    evaluate_with_confusion,\n",
        "    get_eval_transform,\n",
        "    get_train_transform,\n",
        "    load_checkpoint,\n",
        "    train_model,\n",
        ")\n",
        "from fer.losses import LabelSmoothingCE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CSV_PATH = Path(\"path/to/fer2013.csv\")\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "NUM_WORKERS = 4\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "label_names = list(EMOTION_LABELS.values())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions\n",
        "A small wrapper wires up dataloaders, launches training, and then reloads the best checkpoint before computing accuracy and confusion matrices on the private test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def prepare_loaders():\n",
        "    train_tf = get_train_transform()\n",
        "    eval_tf = get_eval_transform()\n",
        "    return build_dataloaders(\n",
        "        str(CSV_PATH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        in_chans=1,\n",
        "        train_transform=train_tf,\n",
        "        eval_transform=eval_tf,\n",
        "    )\n",
        "\n",
        "\n",
        "def run_experiment(run_dir: str, loss: str = \"ce\", smoothing_eps: float = 0.1):\n",
        "    train_loader, val_loader, test_loader = prepare_loaders()\n",
        "    model = EmotionCNN().to(DEVICE)\n",
        "    history = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        epochs=EPOCHS,\n",
        "        device=DEVICE,\n",
        "        loss=loss,\n",
        "        label_smoothing_eps=smoothing_eps,\n",
        "        ckpt_dir=run_dir,\n",
        "    )\n",
        "    load_checkpoint(model, Path(run_dir) / \"best.pt\", DEVICE)\n",
        "\n",
        "    ce_criterion = nn.CrossEntropyLoss()\n",
        "    test_loss, test_acc = evaluate(model, test_loader, ce_criterion, DEVICE)\n",
        "    cm, report = evaluate_with_confusion(model, test_loader, DEVICE)\n",
        "    return {\n",
        "        \"history\": history,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"cm\": cm,\n",
        "        \"report\": report,\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline vs. label smoothing\n",
        "Run two experiments: one with plain cross-entropy and one with label smoothing (`eps=0.1`). The summary table captures overall test accuracy and loss before diving into class-wise confusion.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ce_results = run_experiment(\"runs/ce_baseline\", loss=\"ce\")\n",
        "ls_results = run_experiment(\"runs/label_smoothing_eps01\", loss=\"label_smoothing\", smoothing_eps=0.1)\n",
        "\n",
        "comparison_df = pd.DataFrame(\n",
        "    [\n",
        "        {\"experiment\": \"CrossEntropy\", \"test_acc\": ce_results[\"test_acc\"], \"test_loss\": ce_results[\"test_loss\"]},\n",
        "        {\n",
        "            \"experiment\": \"LabelSmoothing (eps=0.1)\",\n",
        "            \"test_acc\": ls_results[\"test_acc\"],\n",
        "            \"test_loss\": ls_results[\"test_loss\"],\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "comparison_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion matrices\n",
        "Visualize normalized confusion matrices to understand which emotions are most frequently mixed up. Focus especially on Angry/Fear/Sad interactions to see whether label smoothing reduces overconfidence-driven errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_confusion(cm, title):\n",
        "    norm_cm = cm / cm.sum(axis=1, keepdims=True)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(\n",
        "        norm_cm,\n",
        "        xticklabels=label_names,\n",
        "        yticklabels=label_names,\n",
        "        cmap=\"mako\",\n",
        "        annot=False,\n",
        "        cbar_kws={\"label\": \"Normalized frequency\"},\n",
        "        ax=ax,\n",
        "    )\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "plot_confusion(ce_results[\"cm\"], \"Baseline cross-entropy confusion\")\n",
        "plot_confusion(ls_results[\"cm\"], \"Label smoothing confusion (eps=0.1)\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: simulate label noise\n",
        "Use the helper below to flip a percentage of training labels at random, then rerun the experiments with CE, MixUp, and label smoothing to see how performance degrades under noisy supervision.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def inject_noise(df: pd.DataFrame, flip_prob: float = 0.1) -> pd.DataFrame:\n",
        "    # Randomly flip labels to simulate symmetric noise.\n",
        "    noisy = df.copy()\n",
        "    rng = np.random.default_rng(42)\n",
        "    mask = rng.random(len(noisy)) < flip_prob\n",
        "    noisy.loc[mask, \"emotion\"] = rng.integers(0, len(EMOTION_LABELS), size=mask.sum())\n",
        "    return noisy\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# noisy_df = inject_noise(pd.read_csv(CSV_PATH), flip_prob=0.2)\n",
        "# noisy_df.to_csv(\"fer2013_noisy.csv\", index=False)\n",
        "# Then point CSV_PATH to the noisy copy and rerun the experiment cells.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}